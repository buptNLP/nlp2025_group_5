# åœ¨å¯¼å…¥ä»»ä½•å…¶ä»–åº“ä¹‹å‰åº”ç”¨è¡¥ä¸
import os
import sys

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¦ç”¨Streamlitçš„æ–‡ä»¶ç›‘è§†åŠŸèƒ½
os.environ['STREAMLIT_SERVER_WATCH_DIRS'] = 'false'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# å°è¯•ä¿®å¤PyTorchå’ŒStreamlitçš„å…¼å®¹æ€§é—®é¢˜
def patch_torch_for_streamlit():
    try:
        import torch
        
        # åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„åŒ…è£…å™¨ï¼Œé˜²æ­¢Streamlitè®¿é—®torch.classesçš„ç‰¹å®šå±æ€§
        class SafeClassesWrapper:
            def __init__(self, original_module):
                self._original = original_module
                
            def __getattr__(self, name):
                # ç‰¹æ®Šå¤„ç†å¯èƒ½å¯¼è‡´é—®é¢˜çš„å±æ€§
                if name == '__path__' or name.startswith('_'):
                    if hasattr(self._original, name):
                        attr = getattr(self._original, name)
                        # å¦‚æœæ˜¯ä¸€ä¸ªå¯¹è±¡å¹¶ä¸”æœ‰_pathå±æ€§ï¼Œè¿”å›ä¸€ä¸ªå®‰å…¨çš„ä»£ç†
                        if hasattr(attr, '_path'):
                            return type('SafePath', (), {'_path': []})
                        return attr
                    return None
                return getattr(self._original, name)
        
        # æ‰“è¡¥ä¸åˆ°torch.classes
        if hasattr(torch, 'classes'):
            torch.classes = SafeClassesWrapper(torch.classes)
            print("å·²åº”ç”¨PyTorchä¸Streamlitå…¼å®¹æ€§è¡¥ä¸")
    except Exception as e:
        print(f"åº”ç”¨PyTorchè¡¥ä¸æ—¶å‡ºé”™: {e}")

# åº”ç”¨è¡¥ä¸
patch_torch_for_streamlit()


import streamlit as st
import json
import traceback
import sys
import os

# åœ¨å¯¼å…¥ä»»ä½•PyTorchç›¸å…³æ¨¡å—å‰å…ˆåº”ç”¨è¡¥ä¸
if 'fix_torch_streamlit' not in sys.modules:
    try:
        from fix_torch_streamlit import patch_torch_for_streamlit
        patch_torch_for_streamlit()
    except ImportError:
        st.warning("æœªæ‰¾åˆ°PyTorch-Streamlitå…¼å®¹æ€§è¡¥ä¸æ¨¡å—ï¼Œç¨‹åºå¯èƒ½ä¼šä¸ç¨³å®š")

# ç¦ç”¨æ–‡ä»¶ç›‘è§†ä»¥é˜²æ­¢æ®µé”™è¯¯
os.environ['STREAMLIT_SERVER_WATCH_DIRS'] = 'false'

# ç°åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—
from src.document_loader import DocumentLoader
from src.retriever import Retriever
from src.reranker import Reranker
from src.llm import LLM
from src.config import DEFAULT_CHUNK_SIZE, DEFAULT_CHUNK_OVERLAP, DEFAULT_TOP_K, DEFAULT_RERANK_TOP_K
from src.services.retrieval_service import RetrievalService
from src.services.reranking_service import RerankingService
from src.services.generation_service import GenerationService

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æœºå™¨å­¦ä¹ çŸ¥è¯†é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide"
)

def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'llm' not in st.session_state:
        st.session_state.llm = LLM()
    if 'documents' not in st.session_state:
        st.session_state.documents = []

    if 'retrieval_service' not in st.session_state:
        st.session_state.retrieval_service = None
    if 'reranking_service' not in st.session_state:
        st.session_state.reranking_service = None
    if 'generation_service' not in st.session_state:
        st.session_state.generation_service = None

    if 'retriever' not in st.session_state:
        st.session_state.retriever = None
    if 'reranker' not in st.session_state:
        st.session_state.reranker = None
    if 'models_loaded' not in st.session_state:
        st.session_state.models_loaded = False
    if 'references' not in st.session_state:
        st.session_state.references = []

def safe_import_torch_modules():
    """å®‰å…¨å¯¼å…¥PyTorchç›¸å…³æ¨¡å—ï¼Œé˜²æ­¢å´©æºƒ"""
    try:
        # åªæœ‰åœ¨éœ€è¦æ—¶æ‰å¯¼å…¥è¿™äº›æ¨¡å—
        import torch
        import sentence_transformers
        import faiss
        
        # æ£€æŸ¥CUDAå¯ç”¨æ€§ä½†ä¸æ‰“å°è¿‡å¤šä¿¡æ¯
        cuda_available = torch.cuda.is_available()
        device = 'cuda' if cuda_available else 'cpu'
        
        st.session_state.models_loaded = True
        return True
    except Exception as e:
        st.error(f"åŠ è½½æœºå™¨å­¦ä¹ åº“æ—¶å‡ºé”™: {str(e)}")
        st.error(traceback.format_exc())
        return False

# æ›´æ–° app.py ä¸­çš„ chat_interface å‡½æ•°
def chat_interface():
    """ä¼˜åŒ–åçš„å¤šè½®å¯¹è¯ç•Œé¢ï¼Œä¿®å¤HTMLæ¸²æŸ“é—®é¢˜"""
    import streamlit.components.v1 as components
    
    st.header("ğŸ¤– æœºå™¨å­¦ä¹ åŠ©æ‰‹")
    st.markdown("æˆ‘æ˜¯ä¸“ä¸šçš„æœºå™¨å­¦ä¹ åŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€æ•°æ®ç§‘å­¦ç›¸å…³çš„é—®é¢˜ã€‚")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'references_history' not in st.session_state:
        st.session_state.references_history = []
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for idx, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯å¹¶ä¸”æœ‰å¯¹åº”çš„å‚è€ƒèµ„æ–™ï¼Œæ˜¾ç¤ºå‚è€ƒèµ„æ–™ï¼ˆé»˜è®¤æŠ˜å ï¼‰
            if message["role"] == "assistant" and idx//2 < len(st.session_state.references_history):
                refs = st.session_state.references_history[idx//2]
                if refs:
                    
                    # ä½¿ç”¨æ·±è‰²ä¸»é¢˜çš„å‚è€ƒèµ„æ–™å±•ç¤ºåŒº
                    with st.expander("ğŸ“š æŸ¥çœ‹å‚è€ƒèµ„æ–™", expanded=False):
                        # ä½¿ç”¨components.htmlç¡®ä¿HTMLæ­£ç¡®æ¸²æŸ“
                        references_html = f"""
                        <div style="background-color: #212121; padding: 15px; border-radius: 10px;">
                            <h2 style="color: #FFFFFF; margin-top: 0; margin-bottom: 20px; font-size: 24px;">å‚è€ƒæ–‡çŒ®</h2>
                        </div>
                        """
                        
                        for ref_idx, article in enumerate(refs, 1):
                            title = article.get('title', 'æœªçŸ¥æ ‡é¢˜')
                            link = article.get('link', '#')
                            preview = article.get('content_preview', 'æ— æ‘˜è¦')
                            read_count = article.get('read_count', 'æ— é˜…è¯»æ•°æ®')
                            like_count = article.get('like_count', 'æ— ç‚¹èµæ•°æ®')
                            
                            references_html += f"""
                            <div style="background-color: #2D2D2D; border-radius: 10px; padding: 15px; margin-bottom: 15px; border-left: 4px solid #2196F3;">
                                <div style="margin-bottom: 10px;">
                                    <h3 style="color: #2196F3; margin: 0; font-size: 18px;">{ref_idx}. <a href="{link}" target="_blank" style="color: #2196F3; text-decoration: none; font-weight: bold;">{title}</a></h3>
                                </div>
                                
                                <div style="color: #BDBDBD; margin-bottom: 12px; font-size: 14px;">
                                    {preview[:200]}{'...' if len(preview) > 200 else ''}
                                </div>
                                
                                <div style="display: flex; gap: 10px;">
                                    <div style="background-color: rgba(33, 150, 243, 0.2); color: #64B5F6; padding: 4px 10px; border-radius: 4px; font-size: 12px;">
                                        ğŸ“– {read_count}
                                    </div>
                                    <div style="background-color: rgba(76, 175, 80, 0.2); color: #81C784; padding: 4px 10px; border-radius: 4px; font-size: 12px;">
                                        ğŸ‘ {like_count}
                                    </div>
                                </div>
                            </div>
                            """
                        
                        # ä½¿ç”¨components.htmlæ­£ç¡®æ¸²æŸ“HTML
                        components.html(references_html, height=300, scrolling=True)
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ç”ŸæˆåŠ©æ‰‹å›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨æ€è€ƒå¹¶æŸ¥è¯¢ç›¸å…³èµ„æ–™..."):
                response = st.session_state.llm.chat_response(st.session_state.messages)
                
                # æ˜¾ç¤ºå›ç­”å†…å®¹
                st.markdown(response["content"])
                
                # ä¿å­˜æ¶ˆæ¯åˆ°å†å²è®°å½•
                st.session_state.messages.append({"role": "assistant", "content": response["content"]})
                
                # ä¿å­˜å½“å‰å›ç­”çš„å‚è€ƒèµ„æ–™
                st.session_state.references_history.append(response["references"])
                
                # å¦‚æœæœ‰å‚è€ƒèµ„æ–™ï¼Œæ˜¾ç¤ºåœ¨å›ç­”ä¸‹æ–¹
                if response["references"]:
                                        
                    # ä½¿ç”¨æ·±è‰²ä¸»é¢˜çš„å‚è€ƒèµ„æ–™å±•ç¤ºåŒº
                    with st.expander("ğŸ“š æŸ¥çœ‹å‚è€ƒèµ„æ–™", expanded=False):
                        # ä½¿ç”¨components.htmlç¡®ä¿HTMLæ­£ç¡®æ¸²æŸ“
                        references_html = f"""
                        <div style="background-color: #212121; padding: 15px; border-radius: 10px;">
                            <h2 style="color: #FFFFFF; margin-top: 0; margin-bottom: 20px; font-size: 24px;">å‚è€ƒæ–‡çŒ®</h2>
                        </div>
                        """
                        
                        for ref_idx, article in enumerate(response["references"], 1):
                            title = article.get('title', 'æœªçŸ¥æ ‡é¢˜')
                            link = article.get('link', '#')
                            preview = article.get('content_preview', 'æ— æ‘˜è¦')
                            read_count = article.get('read_count', 'æ— é˜…è¯»æ•°æ®')
                            like_count = article.get('like_count', 'æ— ç‚¹èµæ•°æ®')
                            
                            references_html += f"""
                            <div style="background-color: #2D2D2D; border-radius: 10px; padding: 15px; margin-bottom: 15px; border-left: 4px solid #2196F3;">
                                <div style="margin-bottom: 10px;">
                                    <h3 style="color: #2196F3; margin: 0; font-size: 18px;">{ref_idx}. <a href="{link}" target="_blank" style="color: #2196F3; text-decoration: none; font-weight: bold;">{title}</a></h3>
                                </div>
                                
                                <div style="color: #BDBDBD; margin-bottom: 12px; font-size: 14px;">
                                    {preview[:200]}{'...' if len(preview) > 200 else ''}
                                </div>
                                
                                <div style="display: flex; gap: 10px;">
                                    <div style="background-color: rgba(33, 150, 243, 0.2); color: #64B5F6; padding: 4px 10px; border-radius: 4px; font-size: 12px;">
                                        ğŸ“– {read_count}
                                    </div>
                                    <div style="background-color: rgba(76, 175, 80, 0.2); color: #81C784; padding: 4px 10px; border-radius: 4px; font-size: 12px;">
                                        ğŸ‘ {like_count}
                                    </div>
                                </div>
                            </div>
                            """
                        
                        # ä½¿ç”¨components.htmlæ­£ç¡®æ¸²æŸ“HTML
                        components.html(references_html, height=300, scrolling=True)
    
    # æ¸…é™¤å¯¹è¯æŒ‰é’®
    col1, col2 = st.columns([1, 5])
    with col1:
        if st.button("æ¸…é™¤å¯¹è¯å†å²"):
            st.session_state.messages = []
            st.session_state.references_history = []
            st.rerun()

def pdf_qa_interface():
    """PDFæ–‡æ¡£é—®ç­”ç•Œé¢ - ä½¿ç”¨å¾®æœåŠ¡æ¶æ„"""
    st.header("ğŸ“„ PDFæ–‡æ¡£é—®ç­”")
    
    # æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
    show_service_status()
    
    # å‚æ•°é…ç½®
    with st.expander("âš™ï¸ å‚æ•°é…ç½®", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            chunk_size = st.slider("æ–‡æœ¬å—å¤§å°", 200, 1000, DEFAULT_CHUNK_SIZE, 50)
            chunk_overlap = st.slider("æ–‡æœ¬å—é‡å ", 0, 200, DEFAULT_CHUNK_OVERLAP, 10)
        with col2:
            retrieval_top_k = st.slider("æ£€ç´¢æ–‡æ¡£æ•°", 10, 30, 20, 5)
            alpha = st.slider("å‘é‡æ£€ç´¢æƒé‡", 0.0, 1.0, 0.7, 0.1)
        with col3:
            coarse_top_k = st.slider("ç²—æ’ä¿ç•™æ•°", 5, 15, 10, 1)
            fine_top_k = st.slider("ç²¾æ’ä¿ç•™æ•°", 1, 8, 3, 1)
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ PDFæ–‡æ¡£",
        type=['pdf'],
        accept_multiple_files=True,
        help="æ”¯æŒä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶"
    )
    
    if uploaded_files:
        st.success(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # å¤„ç†æ–‡æ¡£å¹¶åˆå§‹åŒ–æœåŠ¡
        if st.button("å¤„ç†æ–‡æ¡£å¹¶åˆå§‹åŒ–æœåŠ¡", key="process_docs"):
            process_documents_and_init_services(
                uploaded_files, chunk_size, chunk_overlap, 
                retrieval_top_k, coarse_top_k, fine_top_k
            )
    
    # é—®ç­”ç•Œé¢
    if all_services_ready():
        st.markdown("---")
        st.markdown("### ğŸ“š å¾®æœåŠ¡åŒ–æ–‡æ¡£é—®ç­”")
        
        query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š")
        
        if query:
            perform_microservice_qa(query, alpha)

def show_service_status():
    """æ˜¾ç¤ºæœåŠ¡çŠ¶æ€"""
    st.markdown("### ğŸ”§ æœåŠ¡çŠ¶æ€")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.session_state.retrieval_service and st.session_state.retrieval_service.is_initialized:
            st.success("ğŸ” æ£€ç´¢æœåŠ¡ï¼šè¿è¡Œä¸­")
            metrics = st.session_state.retrieval_service.get_metrics()
            st.metric("æ£€ç´¢è°ƒç”¨æ¬¡æ•°", metrics['total_calls'])
            if metrics['total_calls'] > 0:
                st.metric("å¹³å‡è€—æ—¶", f"{metrics['avg_time']:.3f}s")
        else:
            st.error("ğŸ” æ£€ç´¢æœåŠ¡ï¼šæœªåˆå§‹åŒ–")
    
    with col2:
        if st.session_state.reranking_service and st.session_state.reranking_service.is_initialized:
            st.success("ğŸ“Š é‡æ’åºæœåŠ¡ï¼šè¿è¡Œä¸­")
            metrics = st.session_state.reranking_service.get_metrics()
            st.metric("é‡æ’åºè°ƒç”¨æ¬¡æ•°", metrics['total_calls'])
            if metrics['total_calls'] > 0:
                st.metric("å¹³å‡è€—æ—¶", f"{metrics['avg_time']:.3f}s")
        else:
            st.error("ğŸ“Š é‡æ’åºæœåŠ¡ï¼šæœªåˆå§‹åŒ–")
    
    with col3:
        if st.session_state.generation_service and st.session_state.generation_service.is_initialized:
            st.success("ğŸ’¬ ç”ŸæˆæœåŠ¡ï¼šè¿è¡Œä¸­")
            metrics = st.session_state.generation_service.get_metrics()
            st.metric("ç”Ÿæˆè°ƒç”¨æ¬¡æ•°", metrics['total_calls'])
            if metrics['total_calls'] > 0:
                st.metric("å¹³å‡è€—æ—¶", f"{metrics['avg_time']:.3f}s")
        else:
            st.error("ğŸ’¬ ç”ŸæˆæœåŠ¡ï¼šæœªåˆå§‹åŒ–")

def process_documents_and_init_services(uploaded_files, chunk_size, chunk_overlap, 
                                      retrieval_top_k, coarse_top_k, fine_top_k):
    """å¤„ç†æ–‡æ¡£å¹¶åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
    # ç¡®ä¿MLåº“å·²åŠ è½½
    if not st.session_state.models_loaded and not safe_import_torch_modules():
        st.error("æœºå™¨å­¦ä¹ æ¨¡å—åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•")
        return
    
    with st.spinner("å¤„ç†æ–‡æ¡£ä¸­..."):
        try:
            # åŠ è½½æ–‡æ¡£
            loader = DocumentLoader(chunk_size, chunk_overlap)
            documents = loader.load_pdf_documents(uploaded_files)
            
            if not documents:
                st.error("æœªèƒ½ä»ä¸Šä¼ çš„æ–‡æ¡£ä¸­æå–åˆ°æœ‰æ•ˆæ–‡æœ¬")
                return
            
            st.session_state.documents = documents
            st.success(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(documents)} ä¸ªæ–‡æœ¬å—")
            
            # åˆå§‹åŒ–æœåŠ¡
            init_success = True
            
            # åˆå§‹åŒ–æ£€ç´¢æœåŠ¡
            st.session_state.retrieval_service = RetrievalService(documents, retrieval_top_k)
            result = st.session_state.retrieval_service.call("test")  # æµ‹è¯•åˆå§‹åŒ–
            if not result['success']:
                init_success = False
# åˆå§‹åŒ–é‡æ’åºæœåŠ¡
            st.session_state.reranking_service = RerankingService(coarse_top_k, fine_top_k)
            result = st.session_state.reranking_service.call("test", [])  # æµ‹è¯•åˆå§‹åŒ–
            if not result['success']:
                init_success = False
            
            # åˆå§‹åŒ–ç”ŸæˆæœåŠ¡
            st.session_state.generation_service = GenerationService()
            result = st.session_state.generation_service.call("test", [])  # æµ‹è¯•åˆå§‹åŒ–
            if not result['success']:
                init_success = False
            
            if init_success:
                st.success("ğŸ‰ æ‰€æœ‰å¾®æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼")
            else:
                st.warning("âš ï¸ éƒ¨åˆ†æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
                
        except Exception as e:
            st.error(f"æ–‡æ¡£å¤„ç†æˆ–æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

def all_services_ready() -> bool:
    """æ£€æŸ¥æ‰€æœ‰æœåŠ¡æ˜¯å¦å°±ç»ª"""
    return (
        st.session_state.retrieval_service and st.session_state.retrieval_service.is_initialized and
        st.session_state.reranking_service and st.session_state.reranking_service.is_initialized and
        st.session_state.generation_service and st.session_state.generation_service.is_initialized
    )

def perform_microservice_qa(query: str, alpha: float):
    """æ‰§è¡Œå¾®æœåŠ¡åŒ–çš„é—®ç­”æµç¨‹"""
    with st.spinner("æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜..."):
        # åˆ›å»ºç»“æœå±•ç¤ºå®¹å™¨
        results_container = st.container()
        
        with results_container:
            # æ˜¾ç¤ºå¤„ç†æµç¨‹
            st.markdown("#### ğŸ”„ å¤„ç†æµç¨‹")
            
            # æ­¥éª¤1ï¼šæ£€ç´¢
            step1_placeholder = st.empty()
            step1_placeholder.info("æ­¥éª¤1: æ··åˆæ£€ç´¢ä¸­...")
            
            retrieval_result = st.session_state.retrieval_service.call(query, alpha)
            
            if not retrieval_result['success']:
                step1_placeholder.error(f"æ£€ç´¢å¤±è´¥: {retrieval_result['error']}")
                return
            
            retrieved_docs = retrieval_result['data']
            retrieval_time = retrieval_result['metrics']['execution_time']
            
            step1_placeholder.success(f"âœ… æ­¥éª¤1å®Œæˆ: æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªæ–‡æ¡£ (è€—æ—¶: {retrieval_time:.3f}s)")
            
            # æ­¥éª¤2ï¼šé‡æ’åº
            step2_placeholder = st.empty()
            step2_placeholder.info("æ­¥éª¤2: ä¸¤é˜¶æ®µé‡æ’åºä¸­...")
            
            reranking_result = st.session_state.reranking_service.call(query, retrieved_docs)
            
            if not reranking_result['success']:
                step2_placeholder.error(f"é‡æ’åºå¤±è´¥: {reranking_result['error']}")
                return
            
            rerank_data = reranking_result['data']
            reranking_time = reranking_result['metrics']['execution_time']
            
            step2_placeholder.success(
                f"âœ… æ­¥éª¤2å®Œæˆ: ç²—æ’â†’{rerank_data['stage_info']['coarse_count']}ä¸ª, "
                f"ç²¾æ’â†’{rerank_data['stage_info']['fine_count']}ä¸ª (è€—æ—¶: {reranking_time:.3f}s)"
            )
            
            # æ­¥éª¤3ï¼šç”Ÿæˆ
            step3_placeholder = st.empty()
            step3_placeholder.info("æ­¥éª¤3: ç”Ÿæˆå›ç­”ä¸­...")
            
            final_docs = rerank_data['fine_ranked']
            generation_result = st.session_state.generation_service.call(query, final_docs)
            
            if not generation_result['success']:
                step3_placeholder.error(f"ç”Ÿæˆå¤±è´¥: {generation_result['error']}")
                return
            
            answer = generation_result['data']
            generation_time = generation_result['metrics']['execution_time']
            
            step3_placeholder.success(f"âœ… æ­¥éª¤3å®Œæˆ: å›ç­”ç”Ÿæˆå®Œæ¯• (è€—æ—¶: {generation_time:.3f}s)")
            
            # æ˜¾ç¤ºç»“æœ
            st.markdown("---")
            st.markdown("#### ğŸ“ ç”Ÿæˆçš„å›ç­”")
            st.write(answer)
            
            # æ˜¾ç¤ºè¯¦ç»†çš„æ£€ç´¢å’Œé‡æ’åºç»“æœ
            show_detailed_results(query, retrieved_docs, rerank_data, final_docs)
            
            # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
            show_performance_summary(retrieval_time, reranking_time, generation_time)

def show_detailed_results(query: str, retrieved_docs, rerank_data, final_docs):
    """æ˜¾ç¤ºè¯¦ç»†çš„æ£€ç´¢å’Œé‡æ’åºç»“æœ"""
    with st.expander("ğŸ” è¯¦ç»†å¤„ç†ç»“æœ", expanded=False):
        tab1, tab2, tab3 = st.tabs(["åŸå§‹æ£€ç´¢ç»“æœ", "ç²—æ’ç»“æœ", "ç²¾æ’ç»“æœ"])
        
        with tab1:
            st.markdown(f"**æ··åˆæ£€ç´¢ç»“æœ** (å…±{len(retrieved_docs)}ä¸ª)")
            for idx, doc in enumerate(retrieved_docs[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                granularity = doc.metadata.get('granularity', 'paragraph')
                source = doc.metadata.get('filename', doc.metadata.get('title', 'æœªçŸ¥æ¥æº'))
                st.markdown(f"**{idx}. [{granularity}çº§åˆ«] {source}**")
                st.markdown(f"```\n{doc.page_content[:200]}...\n```")
        
        with tab2:
            coarse_docs = rerank_data['coarse_ranked']
            st.markdown(f"**ç²—æ’ç»“æœ** (ä»{len(retrieved_docs)}ä¸ªç­›é€‰åˆ°{len(coarse_docs)}ä¸ª)")
            for idx, doc in enumerate(coarse_docs, 1):
                granularity = doc.metadata.get('granularity', 'paragraph')
                source = doc.metadata.get('filename', doc.metadata.get('title', 'æœªçŸ¥æ¥æº'))
                st.markdown(f"**{idx}. [{granularity}çº§åˆ«] {source}**")
                st.markdown(f"```\n{doc.page_content[:200]}...\n```")
        
        with tab3:
            st.markdown(f"**ç²¾æ’ç»“æœ** (æœ€ç»ˆ{len(final_docs)}ä¸ª)")
            for idx, doc in enumerate(final_docs, 1):
                granularity = doc.metadata.get('granularity', 'paragraph')
                source = doc.metadata.get('filename', doc.metadata.get('title', 'æœªçŸ¥æ¥æº'))
                st.markdown(f"**{idx}. [{granularity}çº§åˆ«] {source}**")
                st.markdown(f"```\n{doc.page_content[:300]}...\n```")

def show_performance_summary(retrieval_time: float, reranking_time: float, generation_time: float):
    """æ˜¾ç¤ºæ€§èƒ½æ‘˜è¦"""
    with st.expander("ğŸ“Š æ€§èƒ½ç»Ÿè®¡", expanded=False):
        total_time = retrieval_time + reranking_time + generation_time
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ£€ç´¢è€—æ—¶", f"{retrieval_time:.3f}s")
        with col2:
            st.metric("é‡æ’åºè€—æ—¶", f"{reranking_time:.3f}s")
        with col3:
            st.metric("ç”Ÿæˆè€—æ—¶", f"{generation_time:.3f}s")
        with col4:
            st.metric("æ€»è€—æ—¶", f"{total_time:.3f}s")
        
        # æ€§èƒ½åˆ†æå›¾è¡¨
        st.markdown("**è€—æ—¶åˆ†å¸ƒ**")
        import plotly.express as px
        import pandas as pd
        
        df = pd.DataFrame({
            'é˜¶æ®µ': ['æ£€ç´¢', 'é‡æ’åº', 'ç”Ÿæˆ'],
            'è€—æ—¶(ç§’)': [retrieval_time, reranking_time, generation_time],
            'å æ¯”(%)': [
                retrieval_time/total_time*100,
                reranking_time/total_time*100,
                generation_time/total_time*100
            ]
        })
        
        fig = px.pie(df, values='è€—æ—¶(ç§’)', names='é˜¶æ®µ', title='å„é˜¶æ®µè€—æ—¶åˆ†å¸ƒ')
        st.plotly_chart(fig, use_container_width=True)

def knowledge_base_interface():
    """çŸ¥è¯†åº“å±•ç¤ºç•Œé¢"""
    st.header("ğŸ“š æœºå™¨å­¦ä¹ çŸ¥è¯†åº“")
    
    # åŠ è½½æ–‡ç« æ•°æ®
    loader = DocumentLoader()
    articles = loader.get_knowledge_base_articles()
    
    if not articles:
        st.error("æ— æ³•åŠ è½½çŸ¥è¯†åº“æ–‡ç« ")
        return
    
    # æœç´¢å’Œç­›é€‰
    col1, col2 = st.columns([3, 1])
    with col1:
        search_term = st.text_input("ğŸ” æœç´¢æ–‡ç« ", placeholder="è¾“å…¥å…³é”®è¯æœç´¢...")
    with col2:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["æŒ‰æ ‡é¢˜", "æŒ‰é˜…è¯»é‡", "æŒ‰ç‚¹èµæ•°"])
    
    # ç­›é€‰æ–‡ç« 
    filtered_articles = articles
    if search_term:
        filtered_articles = [
            article for article in articles
            if search_term.lower() in article['title'].lower() or 
               search_term.lower() in article.get('content_preview', '').lower()
        ]
    
    # æ’åº
    if sort_by == "æŒ‰é˜…è¯»é‡":
        def get_read_count(x):
            count = x.get('read_count', '0').replace('é˜…è¯» ', '')
            if count.endswith('k'):
                return int(float(count[:-1]) * 1000)
            elif count.endswith('w'):
                return int(float(count[:-1]) * 10000)
            else:
                return int(count) if count.isdigit() else 0
        
        filtered_articles.sort(key=get_read_count, reverse=True)
    elif sort_by == "æŒ‰ç‚¹èµæ•°":
        filtered_articles.sort(key=lambda x: int(x.get('like_count', '0').replace('èµ', '')), reverse=True)
    else:
        filtered_articles.sort(key=lambda x: x['title'])
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»æ–‡ç« æ•°", len(articles))
    with col2:
        st.metric("æœç´¢ç»“æœ", len(filtered_articles))
    with col3:
        st.metric("å¯ç”¨æ–‡æ¡£", len([a for a in articles if a.get('article_id')]))
    
    # åˆ†é¡µæ˜¾ç¤º
    articles_per_page = 10
    total_pages = (len(filtered_articles) - 1) // articles_per_page + 1
    
    if total_pages > 1:
        page = st.selectbox("é€‰æ‹©é¡µé¢", range(1, total_pages + 1))
    else:
        page = 1
    
    start_idx = (page - 1) * articles_per_page
    end_idx = start_idx + articles_per_page
    page_articles = filtered_articles[start_idx:end_idx]
    
    # æ˜¾ç¤ºæ–‡ç« 
    for article in page_articles:
        with st.container():
            col1, col2 = st.columns([4, 1])
            
            with col1:
                st.markdown(f"### [{article['title']}]({article['link']})")
                if article.get('content_preview'):
                    st.markdown(f"**æ‘˜è¦**: {article['content_preview'][:200]}...")
            
            with col2:
                if article.get('read_count'):
                    st.markdown(f"ğŸ“– {article['read_count']}")
                if article.get('like_count'):
                    st.markdown(f"ğŸ‘ {article['like_count']}")
                if article.get('collect_count'):
                    st.markdown(f"â­ {article['collect_count']}")
            
            st.divider()

def main():
    # åˆå§‹åŒ–
    initialize_session_state()
    
    # ä¾§è¾¹æ å¯¼èˆª
    with st.sidebar:
        st.title("ğŸ¤– MLé—®ç­”ç³»ç»Ÿ")
        page = st.selectbox(
            "é€‰æ‹©åŠŸèƒ½",
            ["å¤šè½®å¯¹è¯", "PDFæ–‡æ¡£é—®ç­”", "çŸ¥è¯†åº“æµè§ˆ"]
        )
        
        st.markdown("---")
        st.markdown("""
        ### ç³»ç»Ÿè¯´æ˜
        - **å¤šè½®å¯¹è¯**: ä¸æœºå™¨å­¦ä¹ åŠ©æ‰‹è¿›è¡Œå¯¹è¯
        - **PDFæ–‡æ¡£é—®ç­”**: ä¸Šä¼ PDFå¹¶è¿›è¡Œé—®ç­”
        - **çŸ¥è¯†åº“æµè§ˆ**: æµè§ˆæœºå™¨å­¦ä¹ æ–‡ç« åº“
        """)
        
    
    # ä¸»ç•Œé¢
    if page == "å¤šè½®å¯¹è¯":
        chat_interface()
    elif page == "PDFæ–‡æ¡£é—®ç­”":
        pdf_qa_interface()
    elif page == "çŸ¥è¯†åº“æµè§ˆ":
        knowledge_base_interface()

if __name__ == "__main__":
    try:
        # è®¾ç½®ä¸€äº›ç¯å¢ƒå˜é‡ï¼Œå‡å°‘PyTorchçš„æ—¥å¿—è¾“å‡º
        os.environ['TOKENIZERS_PARALLELISM'] = 'false'
        
        # è¿è¡Œåº”ç”¨
        main()
    except Exception as e:
        st.error(f"åº”ç”¨ç¨‹åºå‘ç”Ÿé”™è¯¯: {str(e)}")
        st.error(traceback.format_exc())